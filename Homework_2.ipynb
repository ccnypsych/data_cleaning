{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we will use the following datasets from the [National Institute of Alcohol Abuse and Alcoholism](https://pubs.niaaa.nih.gov/publications/aeds/aodprevalence/aodprevalence.htm):\n",
    "* Twelve-month prevalence and population estimates of DSM-IV alcohol abuse by age, sex, and race-ethnicity: United States, 2001–2002 (NESARC) [ txt format](https://pubs.niaaa.nih.gov/publications/aeds/aodprevalence/abusdep1.txt)\n",
    "\n",
    "* Twelve-month prevalence and population estimates of DSM-IV alcohol dependence by age, sex, and race-ethnicity: United States, 2001–2002 (NESARC) [ txt format](https://pubs.niaaa.nih.gov/publications/aeds/aodprevalence/abusdep2.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, we'd like to analyze alcohol abuse and dependency rates. Unfortunately, the dataset we're using can not directly be loaded into a spreadsheet analysis program such as excel or SPSS, so for this assignment we will be cleaning the files and converting them to spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Cleaning the abuse text file\n",
    " The lecture on [files & strings](https://github.com/ccnypsych/psy31170/blob/master/slides/L05_files_strings.ipynb) discusses the steps involved in cleaning the abuse text file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1. Find the file encoding (\"windows-1252\")\n",
    " 2. Open the file using the `with open` syntax\n",
    " 3. Use the `readlines` method to convert the file into a list where each element is a line in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"abusdep1.txt\"\n",
    "with open(filepath, 'r', encoding=\"windows-1252\") as f:\n",
    "    content = f.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Break up the file into blocks-one for each race ethnicity group\n",
    "     1. look for `Total` because that signifies a new group\n",
    "     2. Record each line `Total` appears on \n",
    "     3. Create blocks by indexing into the list of lines in the file using the start and end of each block (which is one less than the beginning of the new block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = []\n",
    "for i, line in enumerate(content):\n",
    "    if 'Total' in line:\n",
    "        print(i, line)\n",
    "        dbs.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create column headers by combining two lines from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex = content[5].split()\n",
    "msmt = content[8].split()\n",
    "columns = [msmt[0]]\n",
    "for s in sex: \n",
    "    for ms in msmt[1:4]:\n",
    "        columns.append(f'{s}-{ms}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Parse each block using [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) to separate the line into individual measurements, loop over the records in block, and store each line as a dictionary\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_block(content, line_number, columns, block_size=5):\n",
    "    block = content[line_number:line_number+block_size]\n",
    "    race_ethnicity = content[line_number-1].strip(\"\\n\")\n",
    "    records = []\n",
    "    for row in block:\n",
    "        record = dict(zip(columns, row.split()))\n",
    "        record['race-ethnicity'] = race_ethnicity\n",
    "        records.append(record)\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Save out the list of records (new table) as a spreadsheet using the csv library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('abuse1.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=columns+['race-ethnicity'])\n",
    "    writer.writeheader()\n",
    "    for row in process_block(content, dbs[1], columns):\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do\n",
    "1. Download the raw text files:\n",
    "    * [abuse](data/abusdep1.txt) \n",
    "    * [dependence](data/abusdep2.txt) \n",
    "2. Using the method discussed above, write code to convert the abuse file and the dependency file to spreadsheets (csvs)\n",
    "3. Run your code and verify your results against the csvs: \n",
    "    * [abuse](data/abuse.csv)\n",
    "    * [dependence](data/dependency.csv)\n",
    "4. Upload to the github assignment 2 submission page\n",
    "\n",
    "All work must be done using Python and you must submit a Jupyter Notebook (such as this file) with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
